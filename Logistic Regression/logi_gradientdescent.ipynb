{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## แบบฝึกหัดเขียนโปรแกรมครั้งที่ 6\n",
    "### Loistic Regression\n",
    "\n",
    "1. เขียนโปรแกรมสำหรับสร้างแบบจำลอง logistic regression ด้วยวิธี gradient descent สำหรับแก้ปัญหา logic AND, OR และ XOR (สำหรับปัญหา XOR ต้องใช้ interaction feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function\n",
    "\n",
    "สูตร sigmoid function \n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "## Cost Function \n",
    "\n",
    "สูตร cost function \\( J(\\theta) \\) สำหรับ logistic regression \n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
    "$$\n",
    "\n",
    "เมื่อ \\( h_\\theta(x) = \\sigma(\\theta^T x) \\) เป็นค่าฟังก์ชันที่ใช้ sigmoid \n",
    "\n",
    "## Gradient Descent Function\n",
    "\n",
    "สูตร update weight ด้วย Gradient descent \n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\frac{\\alpha}{m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Cost function for logistic regression\n",
    "def logistic_cost_function(X, y, weights):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, weights))\n",
    "    cost = (-1/m) * (np.dot(y, np.log(h)) + np.dot((1-y), np.log(1-h)))\n",
    "    return cost\n",
    "\n",
    "# Gradient Descent function\n",
    "def gradient_descent_binary(X, y, weights, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        h = sigmoid(np.dot(X, weights))\n",
    "        weights -= (learning_rate / m) * np.dot(X.T, (h - y))\n",
    "        cost = logistic_cost_function(X, y, weights)\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return weights, cost_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare the Datasets for AND, OR, and XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND dataset\n",
    "X_and = np.array([[1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n",
    "y_and = np.array([0, 0, 0, 1])\n",
    "\n",
    "# OR dataset\n",
    "X_or = np.array([[1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n",
    "y_or = np.array([0, 1, 1, 1])\n",
    "\n",
    "# XOR dataset\n",
    "X_xor = np.array([[1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Predictions: [False False False  True]\n",
      "OR Predictions: [False  True  True  True]\n",
      "XOR Predictions: [False  True  True False]\n"
     ]
    }
   ],
   "source": [
    "# Initial weights\n",
    "initial_weights = np.zeros(X_and.shape[1])\n",
    "\n",
    "# Train AND Logic\n",
    "weights_and, cost_history_and = gradient_descent_binary(X_and, y_and, initial_weights, learning_rate=0.1, iterations=1000)\n",
    "print(\"AND Predictions:\", sigmoid(np.dot(X_and, weights_and)) >= 0.5)\n",
    "\n",
    "# Train OR Logic\n",
    "weights_or, cost_history_or = gradient_descent_binary(X_or, y_or, initial_weights, learning_rate=0.1, iterations=1000)\n",
    "print(\"OR Predictions:\", sigmoid(np.dot(X_or, weights_or)) >= 0.5)\n",
    "\n",
    "# Create interaction feature for XOR\n",
    "X_xor_interaction = np.hstack([X_xor, (X_xor[:, 1] * X_xor[:, 2]).reshape(-1, 1)])\n",
    "\n",
    "# Train XOR Logic\n",
    "weights_xor, cost_history_xor = gradient_descent_binary(X_xor_interaction, y_xor, np.zeros(X_xor_interaction.shape[1]), learning_rate=0.1, iterations=1000)\n",
    "print(\"XOR Predictions:\", sigmoid(np.dot(X_xor_interaction, weights_xor)) >= 0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
